---
output: 
  pdf_document:
    keep_tex: true
header-includes:
    - \usepackage{setspace}\onehalfspacing
---

```{r setup4, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(hrbrthemes)
library(viridis)
library(zoo)
library(stringr)
library(ggrepel)
library(foreign)
library(AER)
library(lmtest)
library(sandwich)
library(texreg)
library(mfx)
options(digits = 8)
options(scipen = 999)
rm(list=ls())
```

```{r, echo = F, include=F}
data = read.csv("data4.csv")
```

# Eksamenssæt 4

## Opgave 1 - Opstil en lineær regressionsmodel for \textit{participation} hvor du bruger de beskrevne forklarende variable.

### (a) - Estimer modellen vha. OLS og kommenter på resultaterne.
For at estimere modellen gøres der brug af LPM, som står for "Linear probability model". LPM bruges da den afhængige variabel "participation" er en binær variabel, hvorfor den kun kan tage værdierne 0 og 1. Hertil betyder 1 deltagelse og 0 betyder ikke-deltagelse. Sandsynligheden for "succes" ($participation = 1$) er givet ved middelværdien for ($E(y)$). Dermed kan modellen opstilles som $$P(y = 1|x) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_4 + \beta_5 x_5 + \beta_6 x_6 + \beta_7 x_7 + u$$Hertil er den estimeret model givet ved $$\hat{y} = \hat{\beta_0} + \hat{\beta_1} x_1 + \hat {\beta_2} x_2 + \hat{\beta_3} x_3 + \hat{\beta_4} x_4 + \hat{\beta_5} x_5 + \hat{\beta_6} x_6 + \hat{\beta_7} x_7 + u$$Her angiver de forskellige $\beta$'er ændringen i sandsynligheden for "succes" (under antagelse at andre faktorer holdes fast) ved en ændring i den pågældende variabel med en enhed. Dog er problematikken her at når værdierne for de uafhængige variable indsættes i modellen, vil man til et punkt nå at y enten er under 0 eller over 1, hvilket vil sige at sandsynligheden enten er negativ eller eller over 100\%.

For LPM gælder det hovedsageligt, at modellen er retvisende når værdierne for de uafhængige variable er tæt på middelværdien. På grund af, at der nødvendigvis er et binært element i LPM, er MLR-antagelsen om homoskedasticitet ikke overholdt. Dermed kan F-test og t-test ikke bruges som normal vis, da variancen for fejlledet ikke er konstant som resultat af heteroskedasticitet, hvorfor estimatorvariancerne er biased. I det følgende vil standardafivigelserne altså blive justeret, hvortil "robust standard errors" udregnes.

```{r}
model_ols = lm(participation ~ income + age + agesq + educ + youngkids + oldkids + foreign, data = data)
robust_ols = coeftest(model_ols, vcov = vcovHC(model_ols, type = "HC0")) #robuste standard afvigelser

screenreg(list(OLS = model_ols, OLS_robust_se = robust_ols), digits = 4)
#summary(model_ols)
```
Alle estimaterne er signifikante på 0,1\%, med undtagelse af "oldkids" som er signifikant på 1\% samt "intercept" og "educ" som begge ikke er signifikante. 
Der er ikke forskel på estimaterne i det der er blevet brugt robuste standard afvigelser for modellen.
Én enheds stigning i det enkelte estimat angiver påvirkningen på den samlede sandsynlighed for "participation". Eksempelvis betyder estimatet "age", at ved at alderen stiger med en enhed, vil sandsynligheden for "participation" stige med 6\%
Det enkelte estimat angiver påvirkningen på sandsynligheden ved en enheds stigning 

### (b) - Test om den partielle effekt af uddannelse er forskellig fra nul.

For at teste hvorvidt den partielle effekt af en variabel er forskellig fra nul bruges en t-test. Hvorvidt nulhypotesen afvises afhænger af den beregnede t-score og dertilhørende p-værdi $$H_0: \beta_4 = 0$$ $$H_1: \beta_4 \neq 0$$ T-scoren beregnes ud fra den estimerede $\beta$ samt den tilhørende standardafvigelse. Dette kan gøres, da nulhypotesen er, at den faktiske værdi er nul, hvorfor dette led ikke indgår i formlen. $$t = \frac{\hat{\beta_j}}{se(\hat{\beta_j})}$$ I nedenstående vil de robuste standardafvigelser blive benyttet til udregningen af t-scoren.

```{r, echo = F}
cat("Kritisk værdi ved 5% = ",qt(1-0.025, df=length(data$educ)-1))
cat("Kritisk værdi vec 1% = ",qt(1-0.005, df=length(data$educ)-1))
```

```{r}
t = 0.0068/0.0059
```

```{r, echo = F}
cat("t-score = ", t)
```

<<<<<<< HEAD
Da t-scoren er under den kritiske værdi kan $H_0$ ikke forkastes. Det samme vil ses i beregningen af p-værdien nedenfor.

```{r, echo = F}
p = 2*(1-pt(t, df=length(data$educ)-1))
cat("P-værdi = ", p)
```

Da p-værdien er højere end det den fastsatte grænse på 5% er resultatet ikke statistisk signifikant. Først ved en grænse tilsvarende p-værdien eller højere vil nulhypotesen forkastes.

### (c) - Test om den partielle effekt af alder er forskellig fra nul.

For at teste hvorvidt alder er statistisk signifikant i modellen bruges en F-test, da alder indgår flere gange, eftersom den kvadrerede alder også er med.

```{r}
linearHypothesis(model_ols, c("age=0", "agesq=0"))
```

## Opgave 2 - Opstil både en logit- og en probit-model for \textit{participation} hvor du bruger de beskrevne forklarende variable.

MANGLER TEKST OM LOGIT OG PROBIT

### (a) - Estimer modellerne.

```{r, include = F}
logit = glm(participation ~ income + age + agesq + educ + youngkids + oldkids + foreign, family = binomial(link = "logit"), data = data)
```

```{r, include = F}
probit = glm(participation ~ income + age + agesq + educ + youngkids + oldkids + foreign, family = binomial(link = "probit"), data = data)
```

```{r}
screenreg(list("LPM OLS" = model_ols, Logit = logit, Probit = probit), digits = 4)
```

Effekten af disse estimater kan ikke direkte aflæses for logit- og probit-regressionerne, grundet den funktion der bruges i disse regressionsmetoder. Dog kan de stadig benyttes til at se signifikansniveau samt fortegn for effekten af variablen. Dermed er $educ$ ikke signifikant i nogle af modellerne, mens de alle har samme fortegn for estimaterne.

### (b) - Test om den partielle effekt af uddannelse er forskellig fra nul.

Her benyttes igen en t-test som i forrige opgave. Igen opstilles følgende hypoteser. $$H_0: \beta_4 = 0$$ $$H_1: \beta_4 \neq 0$$

```{r}
t_logit = 0.0386/0.0302
t_probit = 0.0231/0.0181
```

```{r, echo = F}
cat("t-score for logit = ", t_logit)
cat("t-score for probit = ", t_probit)
```

Da t-værdien for både logit- og probit-regressionen er under den kritiske værdi ved et signifikansniveau på 5% kan $H_0$ ikke forkaset, hvorfor estimatet i begge tilfælde ikke er statistisk signifikant.

```{r}
p_logit = 2*(1-pt(t_logit, df=length(data$educ)-1))
p_probit = 2*(1-pt(t_probit, df=length(data$educ)-1))
```

```{r}
cat("P-værdi for logit = ", p_logit)
cat("P-værdi for probit = ", p_probit)
```

Her ses igen en højere p-værdi end det fastsatte signifikansniveau på 5%, hvilket ligeledes betyder, at $H_0$ ikke kan forkastes. Først ved et signifikansniveau over p-værdien vil $H_0$ kunne forkastes.

### (c) - Test om den partielle effekt af alder er forskellig fra nul vha. et likelihoodratio-test.

For at teste hvorvidt to ellere flere variable er "jointly significant" i en logit- eller probit-regression benyttes en likelihood ratio test. Denne svarer til en F-test for OLS-regressioner. $$LR = 2*(L_{ur}-L_r)$$ Hvor $L_{ur}$ er den begrænsede model uden variablene der testes for. $L$ angiver "log likelihood" for modellen. Der ganges med 2 for at $LR$ er asymptotisk $\chi^2$-fordelt. $$H_0: \beta_2 = \beta_3 = 0$$ $$H_0: \beta_2 = \beta_3 \neq 0$$ Først laves for logit-modellen.

```{r}

logitR = glm(participation ~ income + educ + youngkids + oldkids + foreign, family = binomial(link = "logit"), data = data)
lr_logit = 2*(logLik(logit) - logLik(logitR))
cat("LR = ", as.numeric(lr_logit))

p_logit <- pchisq(lr_logit, df=2, lower.tail = F)
cat("P-værdi = ", as.numeric(p_logit))
```

Da p-værdien er under de normale signifikansniveauer på 5% og 1% forkastes nulhypotesen, hvorfor alder i denne regression er statistisk forskellige fra nul.

Nedenfor laves samme test for probit-modellen.

```{r}
probitR = glm(participation ~ income + educ + youngkids + oldkids + foreign, family = binomial(link = "probit"), data = data)
lr_probit = 2*(logLik(probit) - logLik(probitR))
cat("LR = ", as.numeric(lr_probit))

p_probit <- pchisq(lr_probit, df=2, lower.tail = F)
cat("P-værdi = ", as.numeric(p_probit))
```

Her findes der igen en meget lav p-værdi, og alder i derfor ligeledes forskellig fra nul i denne model, da nulhypotesen om insignifikans forkastes.


## Opgave 3 - Vi vil gerne sammenligne den partielle effekt af \textit{income} på tværs af modellerne. Beregn average partial effect (APE) og kommenter på resultaterne.

BRUGER ROBUST SE

```{r}
ape_logit = logitmfx(logit, data = data, atmean=F, robust = T)
ape_probit = logitmfx(probit, data = data, atmean=T, robust = T)

screenreg(list(ape_logit = ape_logit, ape_probit = ape_probit), digits = 4)
ape_logit
margins(logit, type = "response")
```

## Opgave 4 - Vi vil gerne sammenligne den partielle effekt af \textit{foreign} på tværs af modellerne. Beregn APE og kommenter på resultaterne.

```{r}
cdata <- cbind(1, as.matrix(data[, c("income", "age", "agesq", "educ", "youngkids", "oldkids",
"foreign")]))

cdata1 <- cdata
cdata1[, 8] <- 1

cdata2 <- cdata
cdata2[, 8] <- 0

lcoef <- logit$coefficients
mean(pnorm(cdata1 %*% lcoef) - pnorm(cdata2 %*% lcoef))
```

<<<<<<< HEAD

```{r}
cdata <- cbind(1, as.matrix(data[, c("income", "age", "agesq", "educ", "youngkids", "oldkids",
"foreign")]))

cdata1 <- cdata
cdata1[, 8] <- 1

cdata2 <- cdata
cdata2[, 8] <- 0

pcoef <- probit$coefficients
mean(pnorm(cdata1 %*% pcoef) - pnorm(cdata2 %*% pcoef))
```

## Opgave 5 - Hvorfor er APE at foretrække frem for partial effect at the average (PEA)?

## Opgave 6 - Sammenlign modellernes evne til at prædiktere ved at beregne percent correctly predicted for hver model.
MANGLER FORKLARING AF PCP
```{r}
y <- data["participation"]
lpmpred <- 100*mean((model_ols$fitted > 0.5) == y)
logitpred <- 100*mean((logit$fitted > 0.5) == y)
probitpred <- 100*mean((probit$fitted > 0.5) == y)
PCP <- c(lpmpred,logitpred,probitpred)
names(PCP) <- c("LPM PCP","Logit PCP","Probit PCP")
PCP
```
MANGLER FORTOLKNING
=======
## Opgave 5 - Hvorfor er APE at foretrække frem for partial effect at the average (PEA)?

## Opgave 6 - Sammenlign modellernes evne til at prædiktere ved at beregne percent correctly predicted for hver model.